{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5deb1727-1cde-4d6c-b695-b08ab14d4aa5",
   "metadata": {},
   "source": [
    "# India Kanoon Companion : AI Legal Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0c6c6b-a15c-49fa-bc11-add6b0e2f4b2",
   "metadata": {},
   "source": [
    "### Installing necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2h79UDg8GRjx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2h79UDg8GRjx",
    "outputId": "dead5fe8-0ce7-4a37-8cce-19f282ba5e40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\sifta\\anaconda3\\lib\\site-packages (0.0.208)\n",
      "Requirement already satisfied: deeplake in c:\\users\\sifta\\anaconda3\\lib\\site-packages (3.9.18)\n",
      "Requirement already satisfied: openai in c:\\users\\sifta\\anaconda3\\lib\\site-packages (0.27.8)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\sifta\\anaconda3\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: langchainplus-sdk>=0.0.13 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from langchain) (0.0.20)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from langchain) (2.8.7)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: pillow~=10.2.0 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from deeplake) (10.2.0)\n",
      "Requirement already satisfied: boto3 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from deeplake) (1.34.160)\n",
      "Requirement already satisfied: click in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from deeplake) (8.1.7)\n",
      "Requirement already satisfied: pathos in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from deeplake) (0.3.2)\n",
      "Requirement already satisfied: humbug>=0.3.1 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from deeplake) (0.3.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from deeplake) (4.65.0)\n",
      "Requirement already satisfied: lz4 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from deeplake) (4.3.2)\n",
      "Requirement already satisfied: pyjwt in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from deeplake) (2.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from tiktoken) (2023.10.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from pydantic<2,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.160 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from boto3->deeplake) (1.34.160)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from boto3->deeplake) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from boto3->deeplake) (0.10.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from click->deeplake) (0.4.6)\n",
      "Requirement already satisfied: ppft>=1.7.6.8 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from pathos->deeplake) (1.7.6.8)\n",
      "Requirement already satisfied: dill>=0.3.8 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from pathos->deeplake) (0.3.8)\n",
      "Requirement already satisfied: pox>=0.3.4 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from pathos->deeplake) (0.3.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.16 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from pathos->deeplake) (0.70.16)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from botocore<1.35.0,>=1.34.160->boto3->deeplake) (2.8.2)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (24.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sifta\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.160->boto3->deeplake) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain deeplake openai tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ca3ddc-6b89-4891-9b10-8f36817483c7",
   "metadata": {},
   "source": [
    "### Setting up OPENAI_API_KEY & ACTIVELOOP_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "miExfUTQGnAx",
   "metadata": {
    "id": "miExfUTQGnAx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY']='sk-proj-dajkjkkjldfskldfslk329348989093290CQ1mjekfhZFz'\n",
    "\n",
    "os.environ['ACTIVELOOP_TOKEN']='eyJhbGciOiJub25lIiwidHlwIjoiSldUIn0.fjkdkjdfkjj80948095erwjkfdkml4ti90GRMbzIzcVVWTjJlIn0.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d73c63-1b80-4416-ae00-c9964c429ee0",
   "metadata": {},
   "source": [
    "### Importing necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "HAUU8_JqG8Cu",
   "metadata": {
    "id": "HAUU8_JqG8Cu"
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain import OpenAI\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4a8df6-ec03-460f-814d-6d3e91e2f502",
   "metadata": {},
   "source": [
    "### Splitting by Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72ecbe86-5864-47ea-90f3-7d6a8d48db4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in the document: 40177\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Initialize an empty list to store words\n",
    "words = []\n",
    "\n",
    "# Load the legal document from the .txt file\n",
    "with open('Combined_PDF2Text_Book.txt', 'r', encoding='utf-8') as file:\n",
    "    # Read the entire content of the file\n",
    "    legal_text = file.read()\n",
    "\n",
    "    # Split the text into words\n",
    "    words = legal_text.split()\n",
    "\n",
    "# Now 'words' contains a list of all words in the document\n",
    "print(f\"Total words in the document: {len(words)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e89a2b4f-98c6-4d4e-a10b-80cdfc3b3e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Why',\n",
       " 'Know',\n",
       " 'the',\n",
       " 'Law',\n",
       " 'Understanding',\n",
       " 'the',\n",
       " 'basics',\n",
       " 'of',\n",
       " 'Indian',\n",
       " 'law']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973b5560-3491-4ecc-8a3c-e3bbf90d58fe",
   "metadata": {},
   "source": [
    "### Splitting by Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9ca743e-ad8d-46d3-b22f-efba629a5129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences in the document: 2660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sifta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Download the necessary NLTK data files (only needs to be done once)\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load the legal document from the .txt file\n",
    "with open('Combined_PDF2Text_Book.txt', 'r', encoding='utf-8') as file:\n",
    "    legal_text = file.read()\n",
    "\n",
    "# Split the text into sentences\n",
    "sentences = sent_tokenize(legal_text)\n",
    "\n",
    "# 'sentences' now contains a list of sentences from the document\n",
    "print(f\"Total sentences in the document: {len(sentences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "229eeabe-b016-437f-b38f-999d24a41003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\nWhy Know the Law  Understanding the basics of Indian law is essential for every common man, as it empowers individuals to know their rights and obligations, enabling them to get along with the society.',\n",
       " 'This book aims to make Indian law simple and clear for everyone.',\n",
       " 'We want people to understand how the law works and its importance.',\n",
       " 'As you progress through this book, you will gain insights into the various aspects of Indian law, empowering you to make informed decisions and become a responsible citizen.',\n",
       " \"So, let's embark upon this journey to explore and understand the basics of Indian law together.\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a567553e-5429-4e2a-a8a2-ba67d94b04a0",
   "metadata": {},
   "source": [
    "### Split by Paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c92258d6-aae7-44ec-bb84-055273331763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total paragraphs in the document: 17\n"
     ]
    }
   ],
   "source": [
    "# Load the legal document from the .txt file\n",
    "with open('Combined_PDF2Text_Book.txt', 'r', encoding='utf-8') as file:\n",
    "    legal_text = file.read()\n",
    "\n",
    "# Split the text into paragraphs\n",
    "paragraphs = legal_text.split('\\n\\n')  # Assumes paragraphs are separated by double newlines\n",
    "\n",
    "# 'paragraphs' now contains a list of paragraphs from the document\n",
    "print(f\"Total paragraphs in the document: {len(paragraphs)}\")\n",
    "\n",
    "# Each paragraph can now be used for further processing in question-answering system\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1802c22-813a-4265-9487-cf053cf8bbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " \"Why Know the Law  Understanding the basics of Indian law is essential for every common man, as it empowers individuals to know their rights and obligations, enabling them to get along with the society.  This book aims to make Indian law simple and clear for everyone.  We want people to understand how the law works and its importance.  As you progress through this book, you will gain insights into the various aspects of Indian law, empowering you to make informed decisions and become a responsible citizen.  So, let's embark upon this journey to explore and understand the basics of Indian law together.  A simple Law guide for every Indian  Sree Krishna Seelam  \\x0c  Knowing the law helps:  ● Know your rights and duties: By knowing the law, you understand your rights and can protect yourself. You also get to know what duties you should perform as a citizen.  ● Make correct choices: Understanding the law helps you make correct decisions in life, like in relationships, jobs, making purchases and starting businesses.  ● Solve problems: If you know the law, you can solve conflicts.  ● Stay safe from scams: Knowing the rules can protect you from being  scammed or taken advantage of.  ● Build trust in the legal system: When you understand the law, you see  how the courts and other legal bodies work to keep things fair.  ● Make you live in harmony: When everyone knows the law, people respect each other's rights and solve problems fairly. This helps create a more peaceful society.  In short, knowing the law helps people better their lives, protect their rights, and perform their duties. It also helps people become active and responsible citizens and makes society more peaceful, letting democracy work well for everyone.\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255f7584-7b0b-4d54-a6fa-fede883181ce",
   "metadata": {},
   "source": [
    "### Based on the above three splittings, it is better to use sentences for our use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80e37522-f295-463a-8c90-9e834a27975e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "Why Know the Law  Understanding the basics of Indian law is essential for every common man, as it empowers individuals to know their rights and obligations, enabling them to get along with the society\n",
      "\n",
      "\n",
      "Document 2:\n",
      "This book aims to make Indian law simple and clear for everyone.\n",
      "\n",
      "\n",
      "Document 3:\n",
      "We want people to understand how the law works and its importance.\n",
      "\n",
      "\n",
      "Document 4:\n",
      "As you progress through this book, you will gain insights into the various aspects of Indian law, empowering you to make informed decisions and become a responsible citizen.\n",
      "\n",
      "\n",
      "Document 5:\n",
      "So, let's embark upon this journey to explore and understand the basics of Indian law together.\n",
      "\n",
      "\n",
      "Document 6:\n",
      "A simple Law guide for every Indian  Sree Krishna Seelam  \f",
      "\n",
      "  Knowing the law helps:  ● Know your rights and duties: By knowing the law, you understand your rights and can protect yourself.\n",
      "\n",
      "\n",
      "Document 7:\n",
      "You also get to know what duties you should perform as a citizen.\n",
      "\n",
      "\n",
      "Document 8:\n",
      "● Make correct choices: Understanding the law helps you make correct decisions in life, like in relationships, jobs, making purchases and starting businesses.\n",
      "\n",
      "\n",
      "Document 9:\n",
      "● Solve problems: If you know the law, you can solve conflicts.\n",
      "\n",
      "\n",
      "Document 10:\n",
      "● Stay safe from scams: Knowing the rules can protect you from being  scammed or taken advantage of.\n",
      "\n",
      "\n",
      "Document 11:\n",
      "● Build trust in the legal system: When you understand the law, you see  how the courts and other legal bodies work to keep things fair.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# Convert each chunk into a Document object\n",
    "documents = [Document(page_content=chunk) for chunk in sentences]\n",
    "\n",
    "# Initialize CharacterTextSplitter with desired chunk size and overlap\n",
    "text_splitter = CharacterTextSplitter(chunk_size=2000, chunk_overlap=300)\n",
    "\n",
    "# Split the documents into smaller chunks if necessary\n",
    "# This step might not split further if the documents are already small enough\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# Optionally, print out the split documents to verify\n",
    "for i, doc in enumerate(split_docs):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    print(doc.page_content[:200])  # Print the first 200 characters to check\n",
    "    print(\"\\n\")\n",
    "    if i==10:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd4459a-6646-4459-91e4-face9b339fdc",
   "metadata": {},
   "source": [
    "### Total length of splitted documents/Sentences in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ZKdN2LlfKnKo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZKdN2LlfKnKo",
    "outputId": "a1569250-02f1-4e58-ddc9-1e8e4cdfaa64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2660"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd4f955-af23-4e6b-9f2f-6aa359a1eb1c",
   "metadata": {},
   "source": [
    "### Initializing OpenAIEmebdding and storing documents embeddings in the DeepLake vectore DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "oO3s-0VwKtG0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oO3s-0VwKtG0",
    "outputId": "78cbec94-0df0-40b1-993d-82b7c07b81b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 128 embeddings in 1 batches of size 128:: 100%|█████████████████████████████████| 1/1 [00:44<00:00, 44.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://siftain/Indian_Laws_For_Common_People', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype       shape      dtype  compression\n",
      "  -------    -------     -------    -------  ------- \n",
      "   text       text      (128, 1)      str     None   \n",
      " metadata     json      (128, 1)      str     None   \n",
      " embedding  embedding  (128, 1536)  float32   None   \n",
      "    id        text      (128, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 128 embeddings in 1 batches of size 128:: 100%|█████████████████████████████████| 1/1 [00:47<00:00, 47.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://siftain/Indian_Laws_For_Common_People', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype       shape      dtype  compression\n",
      "  -------    -------     -------    -------  ------- \n",
      "   text       text      (256, 1)      str     None   \n",
      " metadata     json      (256, 1)      str     None   \n",
      " embedding  embedding  (256, 1536)  float32   None   \n",
      "    id        text      (256, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 128 embeddings in 1 batches of size 128:: 100%|█████████████████████████████████| 1/1 [00:58<00:00, 58.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://siftain/Indian_Laws_For_Common_People', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype       shape      dtype  compression\n",
      "  -------    -------     -------    -------  ------- \n",
      "   text       text      (384, 1)      str     None   \n",
      " metadata     json      (384, 1)      str     None   \n",
      " embedding  embedding  (384, 1536)  float32   None   \n",
      "    id        text      (384, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 128 embeddings in 1 batches of size 128:: 100%|█████████████████████████████████| 1/1 [01:28<00:00, 88.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://siftain/Indian_Laws_For_Common_People', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype       shape      dtype  compression\n",
      "  -------    -------     -------    -------  ------- \n",
      "   text       text      (512, 1)      str     None   \n",
      " metadata     json      (512, 1)      str     None   \n",
      " embedding  embedding  (512, 1536)  float32   None   \n",
      "    id        text      (512, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 128 embeddings in 1 batches of size 128:: 100%|████████████████████████████████| 1/1 [01:42<00:00, 102.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://siftain/Indian_Laws_For_Common_People', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype       shape      dtype  compression\n",
      "  -------    -------     -------    -------  ------- \n",
      "   text       text      (640, 1)      str     None   \n",
      " metadata     json      (640, 1)      str     None   \n",
      " embedding  embedding  (640, 1536)  float32   None   \n",
      "    id        text      (640, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 128 embeddings in 1 batches of size 128:: 100%|████████████████████████████████| 1/1 [01:45<00:00, 105.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://siftain/Indian_Laws_For_Common_People', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype       shape      dtype  compression\n",
      "  -------    -------     -------    -------  ------- \n",
      "   text       text      (768, 1)      str     None   \n",
      " metadata     json      (768, 1)      str     None   \n",
      " embedding  embedding  (768, 1536)  float32   None   \n",
      "    id        text      (768, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 128 embeddings in 1 batches of size 128:: 100%|████████████████████████████████| 1/1 [02:13<00:00, 133.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://siftain/Indian_Laws_For_Common_People', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype       shape      dtype  compression\n",
      "  -------    -------     -------    -------  ------- \n",
      "   text       text      (896, 1)      str     None   \n",
      " metadata     json      (896, 1)      str     None   \n",
      " embedding  embedding  (896, 1536)  float32   None   \n",
      "    id        text      (896, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 128 embeddings in 1 batches of size 128:: 100%|████████████████████████████████| 1/1 [02:25<00:00, 145.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://siftain/Indian_Laws_For_Common_People', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype       shape       dtype  compression\n",
      "  -------    -------     -------     -------  ------- \n",
      "   text       text      (1024, 1)      str     None   \n",
      " metadata     json      (1024, 1)      str     None   \n",
      " embedding  embedding  (1024, 1536)  float32   None   \n",
      "    id        text      (1024, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 128 embeddings in 1 batches of size 128:: 100%|████████████████████████████████| 1/1 [02:29<00:00, 149.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://siftain/Indian_Laws_For_Common_People', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype       shape       dtype  compression\n",
      "  -------    -------     -------     -------  ------- \n",
      "   text       text      (1152, 1)      str     None   \n",
      " metadata     json      (1152, 1)      str     None   \n",
      " embedding  embedding  (1152, 1536)  float32   None   \n",
      "    id        text      (1152, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 128 embeddings in 1 batches of size 128:: 100%|█████████████████████████████████| 1/1 [01:34<00:00, 94.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://siftain/Indian_Laws_For_Common_People', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype       shape       dtype  compression\n",
      "  -------    -------     -------     -------  ------- \n",
      "   text       text      (1280, 1)      str     None   \n",
      " metadata     json      (1280, 1)      str     None   \n",
      " embedding  embedding  (1280, 1536)  float32   None   \n",
      "    id        text      (1280, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 128 embeddings in 1 batches of size 128:: 100%|████████████████████████████████| 1/1 [04:33<00:00, 273.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://siftain/Indian_Laws_For_Common_People', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype       shape       dtype  compression\n",
      "  -------    -------     -------     -------  ------- \n",
      "   text       text      (1408, 1)      str     None   \n",
      " metadata     json      (1408, 1)      str     None   \n",
      " embedding  embedding  (1408, 1536)  float32   None   \n",
      "    id        text      (1408, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 128 embeddings in 1 batches of size 128:: 100%|████████████████████████████████| 1/1 [04:00<00:00, 240.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://siftain/Indian_Laws_For_Common_People', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype       shape       dtype  compression\n",
      "  -------    -------     -------     -------  ------- \n",
      "   text       text      (1536, 1)      str     None   \n",
      " metadata     json      (1536, 1)      str     None   \n",
      " embedding  embedding  (1536, 1536)  float32   None   \n",
      "    id        text      (1536, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 128 embeddings in 1 batches of size 128:: 100%|█████████████████████████████████| 1/1 [01:26<00:00, 86.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://siftain/Indian_Laws_For_Common_People', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype       shape       dtype  compression\n",
      "  -------    -------     -------     -------  ------- \n",
      "   text       text      (1664, 1)      str     None   \n",
      " metadata     json      (1664, 1)      str     None   \n",
      " embedding  embedding  (1664, 1536)  float32   None   \n",
      "    id        text      (1664, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 128 embeddings in 1 batches of size 128:: 100%|█████████████████████████████████| 1/1 [00:56<00:00, 56.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://siftain/Indian_Laws_For_Common_People', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype       shape       dtype  compression\n",
      "  -------    -------     -------     -------  ------- \n",
      "   text       text      (1792, 1)      str     None   \n",
      " metadata     json      (1792, 1)      str     None   \n",
      " embedding  embedding  (1792, 1536)  float32   None   \n",
      "    id        text      (1792, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 128 embeddings in 1 batches of size 128:: 100%|█████████████████████████████████| 1/1 [00:59<00:00, 59.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://siftain/Indian_Laws_For_Common_People', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype       shape       dtype  compression\n",
      "  -------    -------     -------     -------  ------- \n",
      "   text       text      (1920, 1)      str     None   \n",
      " metadata     json      (1920, 1)      str     None   \n",
      " embedding  embedding  (1920, 1536)  float32   None   \n",
      "    id        text      (1920, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 128 embeddings in 1 batches of size 128:: 100%|█████████████████████████████████| 1/1 [01:02<00:00, 62.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://siftain/Indian_Laws_For_Common_People', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype       shape       dtype  compression\n",
      "  -------    -------     -------     -------  ------- \n",
      "   text       text      (2048, 1)      str     None   \n",
      " metadata     json      (2048, 1)      str     None   \n",
      " embedding  embedding  (2048, 1536)  float32   None   \n",
      "    id        text      (2048, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 128 embeddings in 1 batches of size 128:: 100%|█████████████████████████████████| 1/1 [01:06<00:00, 66.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://siftain/Indian_Laws_For_Common_People', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype       shape       dtype  compression\n",
      "  -------    -------     -------     -------  ------- \n",
      "   text       text      (2176, 1)      str     None   \n",
      " metadata     json      (2176, 1)      str     None   \n",
      " embedding  embedding  (2176, 1536)  float32   None   \n",
      "    id        text      (2176, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 128 embeddings in 1 batches of size 128:: 100%|█████████████████████████████████| 1/1 [01:07<00:00, 67.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://siftain/Indian_Laws_For_Common_People', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype       shape       dtype  compression\n",
      "  -------    -------     -------     -------  ------- \n",
      "   text       text      (2304, 1)      str     None   \n",
      " metadata     json      (2304, 1)      str     None   \n",
      " embedding  embedding  (2304, 1536)  float32   None   \n",
      "    id        text      (2304, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 128 embeddings in 1 batches of size 128:: 100%|█████████████████████████████████| 1/1 [01:16<00:00, 76.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://siftain/Indian_Laws_For_Common_People', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype       shape       dtype  compression\n",
      "  -------    -------     -------     -------  ------- \n",
      "   text       text      (2432, 1)      str     None   \n",
      " metadata     json      (2432, 1)      str     None   \n",
      " embedding  embedding  (2432, 1536)  float32   None   \n",
      "    id        text      (2432, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 128 embeddings in 1 batches of size 128:: 100%|█████████████████████████████████| 1/1 [01:23<00:00, 83.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://siftain/Indian_Laws_For_Common_People', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype       shape       dtype  compression\n",
      "  -------    -------     -------     -------  ------- \n",
      "   text       text      (2560, 1)      str     None   \n",
      " metadata     json      (2560, 1)      str     None   \n",
      " embedding  embedding  (2560, 1536)  float32   None   \n",
      "    id        text      (2560, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 100 embeddings in 1 batches of size 100:: 100%|█████████████████████████████████| 1/1 [01:18<00:00, 78.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://siftain/Indian_Laws_For_Common_People', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype       shape       dtype  compression\n",
      "  -------    -------     -------     -------  ------- \n",
      "   text       text      (2660, 1)      str     None   \n",
      " metadata     json      (2660, 1)      str     None   \n",
      " embedding  embedding  (2660, 1536)  float32   None   \n",
      "    id        text      (2660, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# creating Deep Lake dataset\n",
    "my_activeloop_org_id = \"siftain\"\n",
    "my_activeloop_dataset_name = \"Indian_Laws_For_Common_People\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)\n",
    "\n",
    "# Adding documents to the Deep Lake dataset\n",
    "# This step processes each document separately to avoid rate limits\n",
    "batch_size = 128 # Defining a batch size to avoid rate limits\n",
    "for i in range(0, len(split_docs), batch_size):\n",
    "    batch = split_docs[i:i+batch_size]\n",
    "    db.add_documents(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d132c8-ddff-423d-8ac3-ec8f6161430a",
   "metadata": {},
   "source": [
    "### Updating the prompt for a chatbot with memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a73215c4-78d6-4852-b36b-73967ffecb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "template = \"\"\"\n",
    "You are a knowledgeable legal assistant. You have access to the following context information:\n",
    "\n",
    "{chunks_formatted}\n",
    "\n",
    "Based on the user's current question and the previous conversation, provide a clear and accurate answer.\n",
    "\n",
    "Previous Conversation: {conversation_history}\n",
    "\n",
    "User Question: {query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chunks_formatted\", \"conversation_history\", \"query\"],\n",
    "    template=template,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9185c9bd-c639-452e-a1d5-b53921ff4644",
   "metadata": {},
   "source": [
    "### Initializing an empty list to store conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "Ro9ffF9dLBjF",
   "metadata": {
    "id": "Ro9ffF9dLBjF"
   },
   "outputs": [],
   "source": [
    "conversation_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bb3674-b076-4ca5-b6da-e1badacb5c5e",
   "metadata": {},
   "source": [
    "### Chatbot Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3352f32f-6e79-4057-b789-a6f0b61e03d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask your legal question:  What are fundamental rights?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Response:\n",
      " Fundamental Rights are essential rights enshrined in Part III of the Constitution of India, which guarantees civil liberty (freedom) and protects individuals from misuse of the power by government. There are six fundamental rights that anchor the Constitution of India, including the right to equality, right to freedom, right against exploitation, right to freedom of religion, cultural and educational rights, and right to constitutional remedies. These rights are considered to be the cornerstone of democracy and are meant to ensure that every citizen of India has equal opportunities and protection under the law.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to ask another question? (yes/no):  yes\n",
      "Ask your legal question:  Write me all the fundamental rights?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Response:\n",
      " \n",
      "There are six fundamental rights enshrined in Part III of the Constitution of India. These include the right to equality, right to freedom, right against exploitation, right to freedom of religion, cultural and educational rights, and right to constitutional remedies. These rights are considered to be the cornerstone of democracy and are meant to ensure that every citizen of India has equal opportunities and protection under the law.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to ask another question? (yes/no):  no\n"
     ]
    }
   ],
   "source": [
    "def handle_chatbot_interaction(query):\n",
    "    \"\"\"\n",
    "    Handles chatbot interaction, remembering the conversation history.\n",
    "    \n",
    "    Parameters:\n",
    "    - query (str): The current question from the user.\n",
    "    - temperature (float): The temperature for the LLM model.\n",
    "    \"\"\"\n",
    "    # Retrieve relevant chunks from the database\n",
    "    docs = db.similarity_search(query)\n",
    "    retrieved_chunks = [doc.page_content for doc in docs]\n",
    "\n",
    "    # Format the conversation history\n",
    "    conversation_formatted = \"\\n\\n\".join(conversation_history)\n",
    "    chunks_formatted = \"\\n\\n\".join(retrieved_chunks)\n",
    "\n",
    "    # Format the prompt\n",
    "    prompt_formatted = prompt.format(chunks_formatted=chunks_formatted, conversation_history=conversation_formatted, query=query)\n",
    "\n",
    "    # Generate the answer\n",
    "    llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "    answer = llm(prompt_formatted)\n",
    "\n",
    "    # Add the current interaction to the conversation history\n",
    "    conversation_history.append(f\"User: {query}\\nAI: {answer}\\n\")\n",
    "\n",
    "    # Return the answer\n",
    "    return answer\n",
    "\n",
    "# Example interaction loop\n",
    "while True:\n",
    "    query = input(\"Ask your legal question: \")\n",
    "    \n",
    "    response = handle_chatbot_interaction(query)\n",
    "    print(\"\\nAI Response:\\n\", response)\n",
    "    \n",
    "    continue_chat = input(\"Do you want to ask another question? (yes/no): \").strip().lower()\n",
    "    if continue_chat != 'yes':\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6e8344d-3776-4304-9061-14a1581e4776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask your legal question:  Tell me about the laws regarding Education?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Response:\n",
      " \n",
      "One of the laws regarding education is the Right to Establish and Administer Educational Institutions, which is outlined in Article 30 of the Indian Constitution. This article allows religious and linguistic minorities to create and manage their own educational institutions according to their choice, as long as they follow sensible rules. This means that these minorities have the right to establish and run their own schools, colleges, and other educational institutions without interference from the government.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to ask another question? (yes/no):  no\n"
     ]
    }
   ],
   "source": [
    "# Example interaction loop\n",
    "while True:\n",
    "    query = input(\"Ask your legal question: \")\n",
    "    \n",
    "    response = handle_chatbot_interaction(query)\n",
    "    print(\"\\nAI Response:\\n\", response)\n",
    "    \n",
    "    continue_chat = input(\"Do you want to ask another question? (yes/no): \").strip().lower()\n",
    "    if continue_chat != 'yes':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "817875e8-afc8-4919-9f09-17c50ecec247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask your legal question:  Tell me about Labour and Employment Law.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Response:\n",
      " \n",
      "Labour and Employment Law is a branch of law that deals with the rights and responsibilities of employers and employees in the workplace. It covers a wide range of topics such as wages, working conditions, discrimination, and workplace safety. Understanding these laws is important in creating fair and respectful workplaces for everyone at the federal, state, and local levels.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to ask another question? (yes/no):  yes\n",
      "Ask your legal question:  What are the different laws for it?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Response:\n",
      " \n",
      "The specific laws for a particular subject can vary depending on the state and level of government. It is important to consult local laws and court rules for clarity on the specific laws that apply to your situation. Each level of government has its own power to make laws for certain subjects.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to ask another question? (yes/no):  yes\n",
      "Ask your legal question:  What is the law which encounters discrimination in work place?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Response:\n",
      " The law that addresses discrimination in the workplace is the Protection against discrimination Act, which was enacted in 2013. This law was influenced by the Vishaka v. State of Rajasthan case, which resulted in guidelines for addressing workplace sexual harassment. The Act also specifically bans gender-based wage discrimination.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to ask another question? (yes/no):  no\n"
     ]
    }
   ],
   "source": [
    "# Example interaction loop\n",
    "while True:\n",
    "    query = input(\"Ask your legal question: \")\n",
    "    \n",
    "    response = handle_chatbot_interaction(query)\n",
    "    print(\"\\nAI Response:\\n\", response)\n",
    "    \n",
    "    continue_chat = input(\"Do you want to ask another question? (yes/no): \").strip().lower()\n",
    "    if continue_chat != 'yes' :\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2bcd8d28-daec-4d57-8b06-67d621a0d85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask your legal question:  I want to know about how my college spend the money taken by students, Is there any law for it?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Response:\n",
      " \n",
      "Yes, there are laws that regulate how colleges can spend the money taken from students. One example is the Higher Education Act, which requires colleges to use federal student aid funds for educational purposes only. Additionally, there may be state laws or regulations that govern how colleges can use student funds. It is important to research and understand these laws to ensure that your college is using student funds appropriately.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to ask another question? (yes/no):  no\n"
     ]
    }
   ],
   "source": [
    "# Example interaction loop\n",
    "while True:\n",
    "    query = input(\"Ask your legal question: \")\n",
    "    \n",
    "    response = handle_chatbot_interaction(query)\n",
    "    print(\"\\nAI Response:\\n\", response)\n",
    "    \n",
    "    continue_chat = input(\"Do you want to ask another question? (yes/no): \").strip().lower()\n",
    "    if continue_chat != 'yes' :\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26f2352-34fc-4876-9c4d-5a5526f3c42f",
   "metadata": {},
   "source": [
    "### If time permits, I Will make different domain specific projects related to Indian Laws."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd56f4c6-bea0-4a89-a5b1-f1f69fb40dfe",
   "metadata": {},
   "source": [
    "# Thank You"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ac4c9c-fb85-4519-9d9c-b6965859c1b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
